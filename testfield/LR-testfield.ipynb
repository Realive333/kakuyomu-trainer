{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb660b0-327f-4168-bf59-aecdcf84f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import work\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608252da-8bc2-4165-aee3-cc3c1e2463e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963\n",
      "370\n",
      "371\n"
     ]
    }
   ],
   "source": [
    "path = f'./tsv/front-512/42'\n",
    "\n",
    "st_time = time.time()\n",
    "BUFFER_SIZE = int(8192*640/8)\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "train = work.load_tsv_dataset(f'{path}/train.tsv')\n",
    "valid = work.load_tsv_dataset(f'{path}/dev.tsv')\n",
    "test = work.load_tsv_dataset(f'{path}/test.tsv')\n",
    "\n",
    "print(len(train))\n",
    "print(len(valid))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9b8476-8d07-4936-ae94-2330a0bf5a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2963/2963 [07:15<00:00,  6.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [00:46<00:00,  7.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 371/371 [00:51<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963 2963\n",
      "370 370\n",
      "371 371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#2,621,440文字が限界#\n",
    "wakati = MeCab.Tagger(\"-Owakati -b 5242880\")\n",
    "\n",
    "for work in tqdm(train):\n",
    "    content = work['content']\n",
    "    work['wakati'] = \"\"\n",
    "    if len(content) > BUFFER_SIZE:\n",
    "        content = content[:BUFFER_SIZE]\n",
    "    parsed = wakati.parse(content)\n",
    "    try:\n",
    "        tokens = parsed.split()\n",
    "    except AttributeError as err:\n",
    "        print(\"error:\", err)\n",
    "        print(\"length:\", len(content))\n",
    "        print(\"content:\", parsed)\n",
    "    work['wakati'] += \" \".join(tokens) + \" \"\n",
    "\n",
    "for work in tqdm(valid):\n",
    "    content = work['content']\n",
    "    work['wakati'] = \"\"\n",
    "    if len(content) > BUFFER_SIZE:\n",
    "        content = content[:BUFFER_SIZE]\n",
    "    parsed = wakati.parse(content)\n",
    "    try:\n",
    "        tokens = parsed.split()\n",
    "    except AttributeError as err:\n",
    "        print(\"error:\", err)\n",
    "        print(\"length:\", len(content))\n",
    "        print(\"content:\", parsed)\n",
    "    work['wakati'] += \" \".join(tokens) + \" \"\n",
    "    \n",
    "for work in tqdm(test):\n",
    "    content = work['content']\n",
    "    work['wakati'] = \"\"\n",
    "    if len(content) > BUFFER_SIZE:\n",
    "        content = content[:BUFFER_SIZE]\n",
    "    parsed = wakati.parse(content)\n",
    "    try:\n",
    "        tokens = parsed.split()\n",
    "    except AttributeError as err:\n",
    "        print(\"error:\", err)\n",
    "        print(\"length:\", len(content))\n",
    "        print(\"content:\", parsed)\n",
    "    work['wakati'] += \" \".join(tokens) + \" \"\n",
    "    \n",
    "x_train = [work['wakati'] for work in train]\n",
    "x_valid = [work['wakati'] for work in valid]\n",
    "x_test  = [work['wakati'] for work in test ]\n",
    "\n",
    "y_train = [work['label'] for work in train]  \n",
    "y_valid = [work['label'] for work in valid]\n",
    "y_test  = [work['label'] for work in test ]\n",
    "\n",
    "del(train)\n",
    "del(valid)\n",
    "del(test)\n",
    "\n",
    "print(len(x_train), len(y_train))\n",
    "print(len(x_valid), len(y_valid))\n",
    "print(len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e001dd71-4a26-4e6c-b2eb-a74f88fd827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:10:25\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "])\n",
    "classifier.fit(x_train, y_train)\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-st_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb477a8-df22-452f-9ff2-b55307e93f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:10:32\n",
      "0.7648648648648648\n"
     ]
    }
   ],
   "source": [
    "predicted = classifier.predict(x_valid)\n",
    "#valid_labels = mlb.inverse_transform(predicted)\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-st_time)))\n",
    "print(accuracy_score(y_valid, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb23fd5-3115-424f-b220-06932e4cd95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:07\n",
      "0.7547169811320755\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "predicted = classifier.predict(x_test)\n",
    "#valid_labels = mlb.inverse_transform(predicted)\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-st_time)))\n",
    "print(accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5949c0e0-e261-425c-9dd2-9fdc6059ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE MODEL ###\n",
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('front512_LR.pkl','wb') as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
