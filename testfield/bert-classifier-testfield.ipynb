{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6985fcb-70cc-4261-a572-31f5af6c852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from os import walk\n",
    "from os import makedirs\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "from transformers import BertJapaneseTokenizer\n",
    "from torch.nn import Softmax\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2dae40-3f7f-4580-b29f-731ad29c4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = torch.load(f'../savepoint/bert-fm/bert-fm-42.pt')\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        out = self.bert(input_ids=tensor_ids, return_dict=True, output_hidden_states=True, output_attentions=True)\n",
    "        vec = out.hidden_states[-1][:,0,:]\n",
    "        vec = vec.view(-1, 768)\n",
    "        o = self.linear(vec)\n",
    "        return F.log_softmax(o), out.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef9b983-fb11-4f24-a541-ce0a248b17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_path = \"../tsv/first-match-scatter/42/test.json\"\n",
    "with open(works_path, \"r\") as f:\n",
    "    works = json.load(f)\n",
    "work = works[100]\n",
    "work_iter = [w['paragraph'] for w in work['contents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecc61a7-ebdc-49c0-99c1-0a767f7e1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\", return_tensors='pt', padding='max_length', max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7393e18-2dd4-4064-a576-a934cad14927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/realive333/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer.batch_encode_plus(work_iter, pad_to_max_length=True, max_length=512, truncation=True, add_special_tokens=True)\n",
    "batch_ids = batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b4f7e1-8677-4b84-87df-56c8813897d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ids = torch.tensor(batch_ids).to('cuda')\n",
    "tensor_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0b8231-53ae-4150-83cb-cb2b6567ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = torch.load(f'../savepoint/bert-fm/bert-fm-42.pt')\n",
    "bert = bert.module.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94707060-1a31-4f2b-8004-69938501e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertPooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n",
      "Linear(in_features=768, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(bert.bert.pooler)\n",
    "print(bert.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e3e717-7a4c-47fc-a8a5-8f435c1d3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bert(tensor_ids, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefe43db-1d4b-465e-9bab-e9c42dfb18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = out.logits\n",
    "last_hidden = out.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e4c788-fb48-4c00-bc96-6010b1e28088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled = bert.bert.pooler(last_hidden)\n",
    "pooled.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "686253e6-e22f-4ca0-a3af-d023a25eda3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3860, -1.4263], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled = bert.bert.pooler(last_hidden)\n",
    "cls_linear = nn.Linear(768, 2).to('cuda')\n",
    "nn.init.normal_(cls_linear.weight, std=0.0001)\n",
    "nn.init.normal_(cls_linear.bias, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e612c466-4b10-41bb-8f95-bb3234565c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_linear.weight = bert.classifier.weight\n",
    "cls_linear.bias = bert.classifier.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59fe5314-2028-4c16-9102-b27b3fe8e579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.classifier.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f8a7ce9-81eb-4158-9402-4b30ce811a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0503,  0.3246],\n",
       "        [-0.1981,  0.5081],\n",
       "        [-0.0189,  0.2033],\n",
       "        [ 0.1545,  0.2322],\n",
       "        [ 0.5509, -0.2223]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_linear(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "951c65ca-55ae-4875-bc5a-c4c604d384dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0503,  0.3246],\n",
      "        [-0.1981,  0.5081],\n",
      "        [-0.0189,  0.2033],\n",
      "        [ 0.1545,  0.2322],\n",
      "        [ 0.5509, -0.2223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7014, -0.5432, -0.6199,  ...,  0.5750,  0.0863, -0.4331],\n",
      "        [ 0.7077, -0.4064, -0.5185,  ...,  0.5127,  0.0337, -0.1763],\n",
      "        [ 0.6667, -0.6674, -0.7178,  ...,  0.6313,  0.1256, -0.2005],\n",
      "        [ 0.7409, -0.5881, -0.6273,  ...,  0.5767,  0.1062, -0.2970],\n",
      "        [ 0.7268, -0.6956, -0.7196,  ...,  0.5405,  0.1342, -0.4827]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0503,  0.3246],\n",
      "        [-0.1981,  0.5081],\n",
      "        [-0.0189,  0.2033],\n",
      "        [ 0.1545,  0.2322],\n",
      "        [ 0.5509, -0.2223]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(logits)\n",
    "print(pooled)\n",
    "print(bert.classifier(pooled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3870eeb8-a878-49c7-96e8-ea861d0166e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7013938426971436,\n",
       " 0.7077224254608154,\n",
       " 0.6667032241821289,\n",
       " 0.7409121990203857,\n",
       " 0.7267847657203674]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s[0] for s in pool_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10ab5828-11fa-4f54-8ad6-40d28334f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_lst = pooled.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38200258-0f29-49a5-ad9c-e20b46033ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1077, 0.2092], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CLS AVERAGE ###\n",
    "sum_lst = list(0 for i in range (768))\n",
    "for lst in pool_lst:\n",
    "    sum_lst = [a+b for a, b in zip(sum_lst, lst)]\n",
    "avg_lst = [a/5 for a in sum_lst]\n",
    "t_avg_lst = torch.tensor(avg_lst).to('cuda')\n",
    "bert.classifier(t_avg_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca6387c9-cb27-45ce-967a-34e8c66dd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLS GRAND ###\n",
    "grand_lst = []\n",
    "for lst in pool_lst:\n",
    "    grand_lst+=lst\n",
    "t_grand_lst = torch.tensor(grand_lst).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09557968-c5bf-4cfd-b792-82aa6661ae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3840])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_w_lst = bert.classifier.weight.tolist()\n",
    "grand_w_lst_l = []\n",
    "grand_w_lst_r = []\n",
    "for i in range(5):\n",
    "    grand_w_lst_l += bert_w_lst[0]\n",
    "    grand_w_lst_r += bert_w_lst[1]\n",
    "grand_w_lst = [grand_w_lst_l, grand_w_lst_r]\n",
    "t_grand_w_lst = torch.tensor(grand_w_lst).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f28b6457-785b-4fe0-86f4-028c50193e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6479, -0.1303], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BERT CLASSIFIER ###\n",
    "gnd_linear = nn.Linear(3840, 2).to('cuda')\n",
    "nn.init.normal_(gnd_linear.weight, std=0.0001)\n",
    "nn.init.normal_(gnd_linear.bias, 0.01)\n",
    "    \n",
    "gnd_linear.weight = torch.nn.Parameter(t_grand_w_lst)\n",
    "gnd_linear.bias = bert.classifier.bias\n",
    "gnd_linear(t_grand_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ef1ba-c4ca-4083-b059-c70116abf148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93049fa4-47b0-4613-91b2-e8785138a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0001,  0.0001], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0107,  0.0009,  ...,  0.0212,  0.0404,  0.0134],\n",
      "        [-0.0114,  0.0242, -0.0184,  ...,  0.0114,  0.0350, -0.0189]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(bert.classifier.bias)\n",
    "print(bert.classifier.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df4bf2c7-5127-4fb9-af79-4930adca0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0167, -0.0170], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0116,  0.0290, -0.0314,  ..., -0.0281,  0.0172,  0.0240],\n",
      "        [-0.0246,  0.0103, -0.0301,  ...,  0.0190, -0.0186, -0.0153]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(cls_linear.bias)\n",
    "print(cls_linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "420ce980-4a4e-466e-9fe9-edaa431bc82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_lst = pooled.to('cpu').tolist()\n",
    "len(pool_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c5bc4f4-39dc-44e9-ae9c-4e477697094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = BertClassifier().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b250db-4cac-47e8-a3bc-83b6ab4718b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cls(tensor_ids))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f505069-dcc9-436b-a2fd-775839b84dae",
   "metadata": {},
   "source": [
    "type(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e69acbc9-146c-47d8-ba1a-42f021704b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0503,  0.3246],\n",
      "        [-0.1981,  0.5081],\n",
      "        [-0.0189,  0.2033],\n",
      "        [ 0.1545,  0.2322],\n",
      "        [ 0.5509, -0.2223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4318, 0.5682],\n",
      "        [0.3305, 0.6695],\n",
      "        [0.4447, 0.5553],\n",
      "        [0.4806, 0.5194],\n",
      "        [0.6842, 0.3158]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.SequenceClassifierOutput"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_n = bert(tensor_ids)\n",
    "print(out_n[0])\n",
    "softmax = nn.Softmax(dim=1)\n",
    "print(softmax(out_n[0]))\n",
    "type(out_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fadbd-d079-44fe-9574-02a7c4eb9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bert(input_ids=tensor_ids, return_dict=True, output_hidden_states=True, output_attentions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f9a45-9e27-44ea-a815-e4093df35d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = out.hidden_states\n",
    "print('last hs', hidden[-1].size())\n",
    "pooled_output = hidden[-1][:, 0, :]\n",
    "print('po', pooled_output.size())\n",
    "pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca81bf6-7b0d-4d72-b709-0114d2d15f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(768, 2).to('cuda')\n",
    "nn.init.normal_(linear.weight, std=0.02)\n",
    "nn.init.normal_(linear.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8a9f1-d090-4c8f-b997-b0e871e9ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooled_output.tolist()\n",
    "pooled = pooled_output.view(-1, 768)\n",
    "linout = linear(pooled_output)\n",
    "\n",
    "print(linout)\n",
    "print(F.softmax(linout, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a8007-2ae3-4b28-a7a2-d996bd2c06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_list = pooled_output.tolist()\n",
    "grand_list = []\n",
    "for l in pooled_list:\n",
    "    grand_list += l\n",
    "print(len(grand_list))\n",
    "t_grand = torch.tensor(grand_list)\n",
    "g_linear = nn.Linear(3840, 2).to('cuda')\n",
    "nn.init.normal_(g_linear.weight, std=0.02)\n",
    "nn.init.normal_(g_linear.bias, 0)\n",
    "\n",
    "g_linout = g_linear(t_grand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be7538-4812-40e8-8999-a3760e47991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "      def __init__(self):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = torch.load(f'../savepoint/bert-fm/bert-fm-42.pt')\n",
    "        self.linear = nn.Linear(768, 9)\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "        def forward(self, input_ids):\n",
    "            vec, _, attentions = self.bert(input_ids, output_attentions=True)\n",
    "            vec = vec[:,0,:]\n",
    "            vec = vec.view(-1, 768)\n",
    "            out = self.linear(vec)\n",
    "            return F.log_softmax(out), attentions\n",
    "\n",
    "classifier = BertClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e3bc9d-698e-4d39-8744-63fc03f43e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertModel"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "bt = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c8aff25-03f8-47e9-80c7-42084f0ce847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertModel'>\n",
      "<class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "print(type(bt))\n",
    "print(type(bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64820680-829d-416a-81d5-1281bb92f0f0",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b5502-ec8d-4c10-96ee-a39f26c9ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"能力 を 持っ てる 霊能 者 に しか でき ない の よ ほー だ から こそ 、 浄霊 の ため の 御 札 なんて いう の が 、 高名 な 人 謹製 って なる と 、 一 つ 凄い 値段 し て 取引 さ れ ちゃう の よ 結局 金 だ な 、 おい 地獄 の 沙汰 も 金 次第 って いう でしょ だ から 祝詞 と か 、 御 札 と か 、 誰 で も 徳 の ある 人物 から 力 を 借り受ける こと が できる ね 、 技術 が それ なり に 発展 し てる の よ 少し で も 多く の 彷徨 える 魂 を 救う ため に 少し で も 才能 が ある 人 が 、 祀ら れ た 存在 から 力 を 借りれる よう に 俺 で も できる の か できる ん じゃ ない 修行 次第 と か だろう けど 適当 だ なぁ まだ いい わ よ 、 モグリ と か だ と 、 そう いう の 考え ず に 除霊 消 霊 、 今 だけ を 解決 し て 後 で 災い に なる こと しでかす やつ が いる ん だ から 消 霊 … … 気 に し ない で 、 あまり 愉快 な 話 で も ない し そう か 、 それ なら 聞か ない で お こう あー で も ない 、 こー で も ない と いい ながら 、 日報 と で も いう べき か 、 今回 の レポート に つい て 少し ずつ 書い て いく 隣 の 相沢 さん は 、 スマホ だっ た タブレット で 打ち込ん で いる が 、 こちら は 手書き で ある 黒沢 君 、 スクロール の 方 手配 し て おく 例え 今後 やら ない と し て も 、 こう いう の 持っ て い て も 損 は ない わ よ あー … … それ じゃあ お 願い でき ます か 今回 は こっち で 料金 は 持っ て おく わ 凄い 怖い の です が 青田 買い よ 、\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c74a1-2aaf-4eda-98db-9c37a9e83eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b82351-0f14-4719-af38-0f09f89debe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = torch.load(f'../savepoint/bert-fm/bert-fm-42.pt')\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f0803-241b-44ed-bc1f-95dc26a7b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import DataParallel\n",
    "model = nn.DataParallel(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c476cd9-298a-482c-8d21-8ff29f5b6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731b747-ac43-4959-a3e7-0d6a0264ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.tokenize(paragraph)\n",
    "tokens = tokenizer.convert_tokens_to_ids(tokenized)\n",
    "wakati_ids = torch.tensor([tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ea46d-f6cc-4813-b785-4054cb268565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wakati_ids)\n",
    "print(wakati_ids.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be604495-34da-4117-bf8a-579cf3004db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bert(tensor_tokens)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767832e-c2d1-4dcf-8354-c477d91f7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = bert(input_ids = wakati_ids, return_dict=True, output_hidden_states=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c6537-b952-4886-9ed1-93003cda4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33a681-6776-4fae-a23d-20545e7e7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid, pool = bert(input_ids = wakati_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfa3f8-23fe-4bb1-ac72-81f923833641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55766090-e829-46bc-8709-4286a1bb779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### これか？\n",
    "o.hidden_states[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124fc40-4390-4f05-bc27-49b50d4c2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "BertModel.from_pretrained('../savepoint/bert-fm/bert-fm-42.bin', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaac89d-190a-480e-8014-f0b8bf7b5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_tokens.Text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46fda5-67d1-4b35-9685-4d07e4a80928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770ef46-3bcf-462d-9529-e7470e3646fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = bert(input_ids=wakati_ids, output_attentions=True).attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb809c9e-223d-420f-9fae-e90aed906b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert(input_ids=wakati_ids, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e9f3e-4ca5-4dd6-9008-6e8176300847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained('../savepoint/bert-fm/bert-fm-42.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13114b21-68e6-495d-a051-9e387d6d24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = model(wakati_ids, output_attentions=True).pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420160a-89cf-460a-b850-2166de3a772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce4f64-6267-4441-82ca-dfeb610a53ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
